---
layout: post
title: "Google Kick Start 2019 Round B Q3 Diverse Subarray"
author: Tikai Chang
tags: ["GKS", "competition", "python"]
comments: true
status: "working"
---

The original question statement is [here](https://codingcompetitions.withgoogle.com/kickstart/round/0000000000050eda/00000000001198c1).

There are N = 1E5 trinkets, not necessary different, lined up linearly. Find a Subarray  index from l to r such that when discarding (confiscated by the customs) *all* repetitive elements repeating more than S times (at most S-1 instances of the same type can be present, *all* confiscated once limit reached), we have the largest number of trinkets remaining (our objective function O).

Let us denote the number of types of trinkets there are as T. First of all, if we were to bruteforce the search, we could calculate the remaining trinkets between l to r in O(T) time. We do this by doing a cumsum over all types T, the counts of a certain inside l to r (inclusive) is equal to cumsum(:r+1)-cumsum(l). Since we do this for all types we have O(T) complexity. Naively: O(N^2 T) complexity. For the small case this should suffice. Dynamical programming with O(1000^3) table filled once per entry.

**Intuitions**: tend all varieties instance number toward S-1.

**Generalities on the optimal solution:** What can we say about the optimal solution? well it must be such that increasing/decreasing r or l will result in a loss in the objective function (local maximum).

**Caterpiller algorithm:** Can we use the two-pointer caterpiller algorithm? start from l = r = 1. move r to the right, if the objective function worsened because it met a too-repetitive-element (TRE), it cannot be a local minimum, so we increase l until we get a move that reduces the status of TRE from the previous rightward movement of r. This means we need to increase l until we get the same type as the TRE and just barely exclude it out.

This movement will have O(N) complexity, moreover, since changes are incremental, we could query the current status in O(1) instead of O(T) mentioned previously. We should in reality have a total complexity of O(N)

(This paragraph was found to be not completely correct <a href = "#correction1">afterwards</a>)
This algo will try to resolve all TRE's, and will find only the subsets of element **without confiscation** at all. We could try to binary search over the number of types confiscated. However, nothing can be inferred to choose the dichotomy properly... So iterating blindly will yield O(N/S) in the worst case scenario. So we get a total complexity of O(N^2/S)

**Divide and conquer:**? Take the optimal solution which includes a few TRE's, can we cut this into chunks with some properties on each chunk that we can exploit? Not that I can think of. Whenever S>2, the TRE's don't even form an atomic border
```
S = 5
1 1 1 2 2 3 4 1 5 6 1 7 8 9 9 1 1 1 1 1
optimal (not unique):
2 2 3 4 1 5 6 1 7 8 9 9 1 1 1
1 2 2 3 4 1 5 6 1 7 8 9 9 1 1
1 1 2 2 3 4 1 5 6 1 7 8 9 9 1
1 1 1 2 2 3 4 1 5 6 1 7 8 9 9
```

The 1's are clearly the TRE in this case, they cut them into 22234 | 56 | 7899.
What we do know is that the left right border *will* be defined by a certain type of TRE. But once again it there are O(N/S) in the worst case scenario. Is there a
better way to choose the bordering TRE? The below is an example where The TRE 2 and 1 can both be chosen as bordering TRE's

```
S = 3
12121212121212
```

**Dynamical programming and recursion:** I can only think about rapidly jump to the next TRE of the same type in a kind of linked list way.

**Partial Ordering:**
If a segment $$A\subset B$$: Then for sure the confiscation (denoted as C) in B will be heavier than A. However there are more elements (denoted as Z) before confiscation , so we can't say much over the overall objective function. O = Z - C.
Let's try to look at Z and C independently:
- $$Z_x = |X|$$
- $$C_x \le |X|$$
- $$A\subset B$$ implies $$ C_A \le C_B $$

**Realization of wrongness:** <a id="correction1"></a>
